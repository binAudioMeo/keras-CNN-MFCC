{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5adf13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35cbf266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from 6903 files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "generalSoundPath = 'Audio-Classification/General-Sounds/'\n",
    "legalVoicePath = 'Audio-Classification/User-Voices/Legal-Voices/'\n",
    "illegalVoicePath = 'Audio-Classification/User-Voices/Illegal-Voices/'\n",
    "\n",
    "features = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(generalSoundPath):\n",
    "    for filename in filenames:\n",
    "        file_name = os.path.join(dirpath, filename)\n",
    "        \n",
    "        class_label = 'General Sound'\n",
    "        data = extract_features(file_name)\n",
    "\n",
    "        features.append([data, class_label])\n",
    "        \n",
    "for dirpath, dirnames, filenames in os.walk(legalVoicePath):\n",
    "    for filename in filenames:\n",
    "        file_name = os.path.join(dirpath, filename)\n",
    "        \n",
    "        class_label = 'Legal Voice'\n",
    "        data = extract_features(file_name)\n",
    "\n",
    "        features.append([data, class_label])\n",
    "        \n",
    "for dirpath, dirnames, filenames in os.walk(illegalVoicePath):\n",
    "    for filename in filenames:\n",
    "        file_name = os.path.join(dirpath, filename)\n",
    "        \n",
    "        class_label = 'Illegal Voice'\n",
    "        data = extract_features(file_name)\n",
    "\n",
    "        features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from', len(featuresdf), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e672e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5225b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_temp, x_test, y_temp, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_temp, y_temp, test_size=0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93028c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74eafc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b7c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 77,059\n",
      "Trainable params: 77,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 32.1506%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100 * score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a755b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "130/130 [==============================] - 2s 4ms/step - loss: 9.1311 - accuracy: 0.4678 - val_loss: 0.8671 - val_accuracy: 0.5959\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86712, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 1.8480 - accuracy: 0.5308 - val_loss: 0.8663 - val_accuracy: 0.6437\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.86712 to 0.86632, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 1.0768 - accuracy: 0.5808 - val_loss: 0.8626 - val_accuracy: 0.6894\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.86632 to 0.86257, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.8980 - accuracy: 0.6245 - val_loss: 0.8026 - val_accuracy: 0.7538\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.86257 to 0.80262, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.8023 - accuracy: 0.6544 - val_loss: 0.7103 - val_accuracy: 0.7603\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.80262 to 0.71030, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.7649 - accuracy: 0.6783 - val_loss: 0.6711 - val_accuracy: 0.7545\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.71030 to 0.67108, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.7171 - accuracy: 0.6887 - val_loss: 0.6112 - val_accuracy: 0.8038\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.67108 to 0.61118, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.7237 - val_loss: 0.5589 - val_accuracy: 0.8081\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.61118 to 0.55894, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7356 - val_loss: 0.5574 - val_accuracy: 0.8168\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.55894 to 0.55740, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.5954 - accuracy: 0.7554 - val_loss: 0.5099 - val_accuracy: 0.8103\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55740 to 0.50994, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7561 - val_loss: 0.4950 - val_accuracy: 0.8240\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.50994 to 0.49499, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.7745 - val_loss: 0.4690 - val_accuracy: 0.8378\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.49499 to 0.46899, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7851 - val_loss: 0.4495 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.46899 to 0.44947, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7901 - val_loss: 0.4267 - val_accuracy: 0.8400\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.44947 to 0.42673, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8104 - val_loss: 0.4248 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.42673 to 0.42482, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.8090 - val_loss: 0.3931 - val_accuracy: 0.8530\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.42482 to 0.39310, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8218 - val_loss: 0.4038 - val_accuracy: 0.8508\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.39310\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8179 - val_loss: 0.3671 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.39310 to 0.36710, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8230 - val_loss: 0.3800 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.36710\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3962 - accuracy: 0.8353 - val_loss: 0.3593 - val_accuracy: 0.8711\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.36710 to 0.35930, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8266 - val_loss: 0.3407 - val_accuracy: 0.8726\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.35930 to 0.34066, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8382 - val_loss: 0.3480 - val_accuracy: 0.8697\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34066\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8445 - val_loss: 0.3254 - val_accuracy: 0.8791\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34066 to 0.32545, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8486 - val_loss: 0.3318 - val_accuracy: 0.8755\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.32545\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3690 - accuracy: 0.8515 - val_loss: 0.3152 - val_accuracy: 0.8878\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.32545 to 0.31525, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3644 - accuracy: 0.8500 - val_loss: 0.3067 - val_accuracy: 0.8878\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.31525 to 0.30668, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8585 - val_loss: 0.3042 - val_accuracy: 0.8870\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.30668 to 0.30417, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8614 - val_loss: 0.2995 - val_accuracy: 0.8950\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.30417 to 0.29949, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3443 - accuracy: 0.8624 - val_loss: 0.2995 - val_accuracy: 0.8993\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.29949 to 0.29945, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8624 - val_loss: 0.2851 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.29945 to 0.28506, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8698 - val_loss: 0.2695 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.28506 to 0.26953, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8766 - val_loss: 0.2722 - val_accuracy: 0.9015\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.26953\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8809 - val_loss: 0.2587 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.26953 to 0.25875, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8788 - val_loss: 0.2688 - val_accuracy: 0.9102\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.25875\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8822 - val_loss: 0.2606 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.25875\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3026 - accuracy: 0.8812 - val_loss: 0.2677 - val_accuracy: 0.9066\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.25875\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8771 - val_loss: 0.2545 - val_accuracy: 0.9037\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.25875 to 0.25451, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.8863 - val_loss: 0.2519 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.25451 to 0.25194, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8933 - val_loss: 0.2431 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.25194 to 0.24310, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.8908 - val_loss: 0.2562 - val_accuracy: 0.9095\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.24310\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8954 - val_loss: 0.2426 - val_accuracy: 0.9088\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.24310 to 0.24258, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8986 - val_loss: 0.2220 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.24258 to 0.22204, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8904 - val_loss: 0.2403 - val_accuracy: 0.9182\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.22204\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8974 - val_loss: 0.2415 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.22204\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.9022 - val_loss: 0.2151 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.22204 to 0.21508, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2388 - accuracy: 0.9046 - val_loss: 0.2395 - val_accuracy: 0.9138\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.21508\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2571 - accuracy: 0.8962 - val_loss: 0.2332 - val_accuracy: 0.9167\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.21508\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2403 - accuracy: 0.9063 - val_loss: 0.2213 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.21508\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9036 - val_loss: 0.2127 - val_accuracy: 0.9363\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.21508 to 0.21266, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.9061 - val_loss: 0.2139 - val_accuracy: 0.9341\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21266\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9140 - val_loss: 0.2214 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21266\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2349 - accuracy: 0.9131 - val_loss: 0.2412 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.21266\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2165 - accuracy: 0.9174 - val_loss: 0.2233 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.21266\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 0s 3ms/step - loss: 0.2455 - accuracy: 0.9097 - val_loss: 0.2087 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.21266 to 0.20874, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2290 - accuracy: 0.9119 - val_loss: 0.2221 - val_accuracy: 0.9153\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.20874\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 0.2317 - accuracy: 0.9085 - val_loss: 0.2061 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.20874 to 0.20615, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.2172 - accuracy: 0.9160 - val_loss: 0.2155 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.20615\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.2128 - accuracy: 0.9193 - val_loss: 0.2078 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.20615\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.2155 - accuracy: 0.9193 - val_loss: 0.2038 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.20615 to 0.20377, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.2227 - accuracy: 0.9133 - val_loss: 0.1911 - val_accuracy: 0.9341\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.20377 to 0.19110, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.2237 - accuracy: 0.9138 - val_loss: 0.2054 - val_accuracy: 0.9240\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.19110\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.2315 - accuracy: 0.9167 - val_loss: 0.2117 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.19110\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.1990 - accuracy: 0.9213 - val_loss: 0.1958 - val_accuracy: 0.9348\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.19110\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1964 - accuracy: 0.9256 - val_loss: 0.1916 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.19110\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.2102 - accuracy: 0.9184 - val_loss: 0.2293 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.19110\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.2072 - accuracy: 0.9215 - val_loss: 0.1901 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.19110 to 0.19010, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1985 - accuracy: 0.9210 - val_loss: 0.1935 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.19010\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.2018 - accuracy: 0.9201 - val_loss: 0.1913 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.19010\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.1832 - accuracy: 0.9300 - val_loss: 0.1865 - val_accuracy: 0.9385\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.19010 to 0.18650, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1982 - accuracy: 0.9242 - val_loss: 0.1887 - val_accuracy: 0.9399\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.18650\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1950 - accuracy: 0.9290 - val_loss: 0.1780 - val_accuracy: 0.9421\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.18650 to 0.17801, saving model to saved_models\\weights.best.basic_mlp.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1858 - accuracy: 0.9266 - val_loss: 0.1997 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.17801\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.1959 - accuracy: 0.9266 - val_loss: 0.1899 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.17801\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.1898 - accuracy: 0.9271 - val_loss: 0.1869 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.17801\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.1935 - accuracy: 0.9239 - val_loss: 0.1852 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.17801\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1880 - accuracy: 0.9290 - val_loss: 0.1978 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.17801\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.1883 - accuracy: 0.9297 - val_loss: 0.2037 - val_accuracy: 0.9254\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.17801\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 1s 7ms/step - loss: 0.1931 - accuracy: 0.9266 - val_loss: 0.2026 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.17801\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1857 - accuracy: 0.9305 - val_loss: 0.1917 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.17801\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1977 - accuracy: 0.9261 - val_loss: 0.1993 - val_accuracy: 0.9254\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.17801\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1765 - accuracy: 0.9321 - val_loss: 0.2053 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.17801\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1625 - accuracy: 0.9384 - val_loss: 0.1852 - val_accuracy: 0.9413\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.17801\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1983 - accuracy: 0.9288 - val_loss: 0.2076 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.17801\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1955 - accuracy: 0.9283 - val_loss: 0.2159 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.17801\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1787 - accuracy: 0.9346 - val_loss: 0.2063 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.17801\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1604 - accuracy: 0.9375 - val_loss: 0.1923 - val_accuracy: 0.9247\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.17801\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1644 - accuracy: 0.9391 - val_loss: 0.1928 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.17801\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1726 - accuracy: 0.9341 - val_loss: 0.1834 - val_accuracy: 0.9341\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.17801\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1723 - accuracy: 0.9375 - val_loss: 0.1813 - val_accuracy: 0.9341\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.17801\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1641 - accuracy: 0.9375 - val_loss: 0.1777 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.17801 to 0.17767, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1902 - accuracy: 0.9300 - val_loss: 0.1877 - val_accuracy: 0.9290\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.17767\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1702 - accuracy: 0.9355 - val_loss: 0.2000 - val_accuracy: 0.9261\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.17767\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1772 - accuracy: 0.9370 - val_loss: 0.1824 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.17767\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1681 - accuracy: 0.9343 - val_loss: 0.1917 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.17767\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1806 - accuracy: 0.9401 - val_loss: 0.1929 - val_accuracy: 0.9319\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.17767\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1601 - accuracy: 0.9423 - val_loss: 0.1801 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.17767\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1675 - accuracy: 0.9413 - val_loss: 0.1873 - val_accuracy: 0.9196\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.17767\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1724 - accuracy: 0.9343 - val_loss: 0.1820 - val_accuracy: 0.9341\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.17767\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 1s 9ms/step - loss: 0.1763 - accuracy: 0.9324 - val_loss: 0.1930 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.17767\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 1s 8ms/step - loss: 0.1703 - accuracy: 0.9382 - val_loss: 0.1949 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.17767\n",
      "Training completed in time:  0:01:13.074476\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_val, y_val), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f800f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['General Sound' 'Illegal Voice' 'Legal Voice']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "y_pred = model.predict_classes(x_test)\n",
    "confusion_mat = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "print(le.classes_)\n",
    "\n",
    "plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.cm.gray)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "ticks = np.arange(3)\n",
    "plt.xticks(ticks, ticks)\n",
    "plt.yticks(ticks, ticks)\n",
    "plt.ylabel('True labels')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0663648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9664332270622253\n",
      "Validation Accuracy:  0.9326574802398682\n",
      "Testing Accuracy:  0.9196234345436096\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Validation Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644c0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = np.array([extract_features(file_name)])\n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9fa28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: Legal Voice \n",
      "\n",
      "General Sound \t\t :  0.24346783757209777832031250000000\n",
      "Illegal Voice \t\t :  0.37769892811775207519531250000000\n",
      "Legal Voice \t\t :  0.37883323431015014648437500000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "filename = 'V-YT-PSY-006051.wav'\n",
    "# Legal\n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da318c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
