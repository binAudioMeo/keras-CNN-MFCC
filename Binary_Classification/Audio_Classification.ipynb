{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5adf13cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35cbf266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from 7361 files\n"
     ]
    }
   ],
   "source": [
    "# Load various imports \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "generalSoundPath = 'Audio-Classification/General-Sounds/'\n",
    "legalVoicePath = 'Audio-Classification/User-Voices/Legal-Voices/'\n",
    "illegalVoicePath = 'Audio-Classification/User-Voices/Illegal-Voices/'\n",
    "\n",
    "features = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(generalSoundPath):\n",
    "    for filename in filenames:\n",
    "        file_name = os.path.join(dirpath, filename)\n",
    "        \n",
    "        class_label = 'General Sound'\n",
    "        data = extract_features(file_name)\n",
    "\n",
    "        features.append([data, class_label])\n",
    "        \n",
    "for dirpath, dirnames, filenames in os.walk(legalVoicePath):\n",
    "    for filename in filenames:\n",
    "        file_name = os.path.join(dirpath, filename)\n",
    "        \n",
    "        class_label = 'Legal Voice'\n",
    "        data = extract_features(file_name)\n",
    "\n",
    "        features.append([data, class_label])\n",
    "        \n",
    "for dirpath, dirnames, filenames in os.walk(illegalVoicePath):\n",
    "    for filename in filenames:\n",
    "        file_name = os.path.join(dirpath, filename)\n",
    "        \n",
    "        class_label = 'Illegal Voice'\n",
    "        data = extract_features(file_name)\n",
    "\n",
    "        features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from', len(featuresdf), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e672e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d5225b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({2: 1849, 0: 1527, 1: 1040})\n",
      "Counter({2: 644, 0: 473, 1: 355})\n",
      "Counter({2: 588, 0: 552, 1: 333})\n"
     ]
    }
   ],
   "source": [
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "from collections import Counter\n",
    "\n",
    "x_temp, x_test, y_temp, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_temp, y_temp, test_size=0.25, random_state = 42)\n",
    "\n",
    "print(Counter(np.argmax(y_train, axis=1)))\n",
    "print(Counter(np.argmax(y_val, axis=1)))\n",
    "print(Counter(np.argmax(y_test, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93028c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics \n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74eafc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b7c56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               10496     \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 77,059\n",
      "Trainable params: 77,059\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Pre-training accuracy: 39.0360%\n"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()\n",
    "\n",
    "# Calculate pre-training accuracy \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "accuracy = 100 * score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a755b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "138/138 [==============================] - 5s 13ms/step - loss: 8.7845 - accuracy: 0.4549 - val_loss: 0.8874 - val_accuracy: 0.6230\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.88738, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 1.7967 - accuracy: 0.5208 - val_loss: 0.9253 - val_accuracy: 0.6352\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.88738\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 1.0558 - accuracy: 0.5630 - val_loss: 0.8817 - val_accuracy: 0.6236\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.88738 to 0.88167, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.9291 - accuracy: 0.6089 - val_loss: 0.8248 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.88167 to 0.82479, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.8262 - accuracy: 0.6458 - val_loss: 0.7524 - val_accuracy: 0.7554\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.82479 to 0.75238, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 6/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.7579 - accuracy: 0.6750 - val_loss: 0.6778 - val_accuracy: 0.7643\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.75238 to 0.67779, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.7098 - accuracy: 0.6952 - val_loss: 0.6434 - val_accuracy: 0.7663\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.67779 to 0.64340, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.6807 - accuracy: 0.7129 - val_loss: 0.6061 - val_accuracy: 0.7717\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.64340 to 0.60610, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.6173 - accuracy: 0.7355 - val_loss: 0.5599 - val_accuracy: 0.7745\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.60610 to 0.55991, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.6038 - accuracy: 0.7423 - val_loss: 0.5486 - val_accuracy: 0.7697\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.55991 to 0.54860, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.5882 - accuracy: 0.7473 - val_loss: 0.5166 - val_accuracy: 0.7677\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.54860 to 0.51661, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.5574 - accuracy: 0.7649 - val_loss: 0.4845 - val_accuracy: 0.8166\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.51661 to 0.48445, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.5216 - accuracy: 0.7842 - val_loss: 0.4621 - val_accuracy: 0.8186\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.48445 to 0.46206, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.5228 - accuracy: 0.7865 - val_loss: 0.4374 - val_accuracy: 0.8302\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.46206 to 0.43741, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.4881 - accuracy: 0.7964 - val_loss: 0.4519 - val_accuracy: 0.8152\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.43741\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.4834 - accuracy: 0.8021 - val_loss: 0.4279 - val_accuracy: 0.8268\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.43741 to 0.42788, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.4529 - accuracy: 0.8116 - val_loss: 0.3971 - val_accuracy: 0.8465\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.42788 to 0.39707, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.4382 - accuracy: 0.8159 - val_loss: 0.3866 - val_accuracy: 0.8499\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.39707 to 0.38659, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.4306 - accuracy: 0.8247 - val_loss: 0.3624 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.38659 to 0.36238, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.4151 - accuracy: 0.8338 - val_loss: 0.3636 - val_accuracy: 0.8492\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.36238\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.4197 - accuracy: 0.8331 - val_loss: 0.3506 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.36238 to 0.35059, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3968 - accuracy: 0.8415 - val_loss: 0.3554 - val_accuracy: 0.8587\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.35059\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3731 - accuracy: 0.8492 - val_loss: 0.3471 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.35059 to 0.34714, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3923 - accuracy: 0.8433 - val_loss: 0.3263 - val_accuracy: 0.8845\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.34714 to 0.32628, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3658 - accuracy: 0.8603 - val_loss: 0.3273 - val_accuracy: 0.8804\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.32628\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3792 - accuracy: 0.8528 - val_loss: 0.3210 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.32628 to 0.32098, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.3499 - accuracy: 0.8596 - val_loss: 0.3196 - val_accuracy: 0.8743\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.32098 to 0.31961, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.3402 - accuracy: 0.8632 - val_loss: 0.2972 - val_accuracy: 0.8879\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.31961 to 0.29725, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3289 - accuracy: 0.8675 - val_loss: 0.3094 - val_accuracy: 0.8940\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.29725\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3357 - accuracy: 0.8668 - val_loss: 0.2963 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.29725 to 0.29631, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3299 - accuracy: 0.8653 - val_loss: 0.3034 - val_accuracy: 0.8730\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.29631\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.3065 - accuracy: 0.8836 - val_loss: 0.2969 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.29631\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.3091 - accuracy: 0.8798 - val_loss: 0.2704 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.29631 to 0.27038, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.3004 - accuracy: 0.8766 - val_loss: 0.2863 - val_accuracy: 0.9049\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.27038\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 8ms/step - loss: 0.3030 - accuracy: 0.8832 - val_loss: 0.2846 - val_accuracy: 0.8886\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.27038\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.3102 - accuracy: 0.8788 - val_loss: 0.2824 - val_accuracy: 0.9049\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.27038\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2975 - accuracy: 0.8745 - val_loss: 0.2866 - val_accuracy: 0.9042\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.27038\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2890 - accuracy: 0.8893 - val_loss: 0.2847 - val_accuracy: 0.8981\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.27038\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2844 - accuracy: 0.8902 - val_loss: 0.2693 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.27038 to 0.26927, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2824 - accuracy: 0.8852 - val_loss: 0.2666 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.26927 to 0.26656, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2859 - accuracy: 0.8845 - val_loss: 0.2689 - val_accuracy: 0.9015\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.26656\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2715 - accuracy: 0.8922 - val_loss: 0.2678 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.26656\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2607 - accuracy: 0.8983 - val_loss: 0.2694 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.26656\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2662 - accuracy: 0.8920 - val_loss: 0.2546 - val_accuracy: 0.9029\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.26656 to 0.25462, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2666 - accuracy: 0.8958 - val_loss: 0.2568 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.25462\n",
      "Epoch 46/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2469 - accuracy: 0.9029 - val_loss: 0.2516 - val_accuracy: 0.8981\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.25462 to 0.25163, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2538 - accuracy: 0.9029 - val_loss: 0.2420 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.25163 to 0.24202, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2736 - accuracy: 0.8927 - val_loss: 0.2617 - val_accuracy: 0.9056\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.24202\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2548 - accuracy: 0.8981 - val_loss: 0.2354 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.24202 to 0.23541, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2333 - accuracy: 0.9128 - val_loss: 0.2540 - val_accuracy: 0.9015\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.23541\n",
      "Epoch 51/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2509 - accuracy: 0.9022 - val_loss: 0.2607 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.23541\n",
      "Epoch 52/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2316 - accuracy: 0.9117 - val_loss: 0.2366 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.23541\n",
      "Epoch 53/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2318 - accuracy: 0.9094 - val_loss: 0.2526 - val_accuracy: 0.9042\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.23541\n",
      "Epoch 54/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2333 - accuracy: 0.9076 - val_loss: 0.2516 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.23541\n",
      "Epoch 55/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2236 - accuracy: 0.9087 - val_loss: 0.2607 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.23541\n",
      "Epoch 56/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2381 - accuracy: 0.9033 - val_loss: 0.2563 - val_accuracy: 0.9062\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.23541\n",
      "Epoch 57/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2268 - accuracy: 0.9062 - val_loss: 0.2282 - val_accuracy: 0.9226\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.23541 to 0.22819, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 58/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.2317 - accuracy: 0.9106 - val_loss: 0.2405 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.22819\n",
      "Epoch 59/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2146 - accuracy: 0.9158 - val_loss: 0.2490 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.22819\n",
      "Epoch 60/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.1956 - accuracy: 0.9192 - val_loss: 0.2524 - val_accuracy: 0.9049\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.22819\n",
      "Epoch 61/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2160 - accuracy: 0.9126 - val_loss: 0.2365 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.22819\n",
      "Epoch 62/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2160 - accuracy: 0.9189 - val_loss: 0.2372 - val_accuracy: 0.9178\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.22819\n",
      "Epoch 63/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2215 - accuracy: 0.9219 - val_loss: 0.2242 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.22819 to 0.22424, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 64/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2296 - accuracy: 0.9083 - val_loss: 0.2541 - val_accuracy: 0.9083\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.22424\n",
      "Epoch 65/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2186 - accuracy: 0.9201 - val_loss: 0.2483 - val_accuracy: 0.9124\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.22424\n",
      "Epoch 66/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.1992 - accuracy: 0.9226 - val_loss: 0.2569 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.22424\n",
      "Epoch 67/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2050 - accuracy: 0.9169 - val_loss: 0.2543 - val_accuracy: 0.9090\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.22424\n",
      "Epoch 68/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2017 - accuracy: 0.9216 - val_loss: 0.2572 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.22424\n",
      "Epoch 69/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.2155 - accuracy: 0.9117 - val_loss: 0.2940 - val_accuracy: 0.8893\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.22424\n",
      "Epoch 70/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.2018 - accuracy: 0.9203 - val_loss: 0.2408 - val_accuracy: 0.9185\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.22424\n",
      "Epoch 71/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2005 - accuracy: 0.9262 - val_loss: 0.2362 - val_accuracy: 0.9232\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.22424\n",
      "Epoch 72/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.1968 - accuracy: 0.9221 - val_loss: 0.2316 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.22424\n",
      "Epoch 73/100\n",
      "138/138 [==============================] - 1s 8ms/step - loss: 0.2013 - accuracy: 0.9223 - val_loss: 0.2528 - val_accuracy: 0.9076\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.22424\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 1s 7ms/step - loss: 0.1945 - accuracy: 0.9269 - val_loss: 0.2567 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.22424\n",
      "Epoch 75/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2066 - accuracy: 0.9244 - val_loss: 0.2400 - val_accuracy: 0.9185\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.22424\n",
      "Epoch 76/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.2002 - accuracy: 0.9237 - val_loss: 0.2585 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.22424\n",
      "Epoch 77/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.2063 - accuracy: 0.9271 - val_loss: 0.2601 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.22424\n",
      "Epoch 78/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1999 - accuracy: 0.9207 - val_loss: 0.2476 - val_accuracy: 0.9103\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.22424\n",
      "Epoch 79/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1888 - accuracy: 0.9298 - val_loss: 0.2495 - val_accuracy: 0.9117\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.22424\n",
      "Epoch 80/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1837 - accuracy: 0.9269 - val_loss: 0.2485 - val_accuracy: 0.9158\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.22424\n",
      "Epoch 81/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1940 - accuracy: 0.9280 - val_loss: 0.2435 - val_accuracy: 0.9069\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.22424\n",
      "Epoch 82/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1779 - accuracy: 0.9266 - val_loss: 0.2696 - val_accuracy: 0.9110\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.22424\n",
      "Epoch 83/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1973 - accuracy: 0.9291 - val_loss: 0.2446 - val_accuracy: 0.9185\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.22424\n",
      "Epoch 84/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1874 - accuracy: 0.9241 - val_loss: 0.2235 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.22424 to 0.22354, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 85/100\n",
      "138/138 [==============================] - 1s 5ms/step - loss: 0.1769 - accuracy: 0.9316 - val_loss: 0.2516 - val_accuracy: 0.9158\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.22354\n",
      "Epoch 86/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1722 - accuracy: 0.9318 - val_loss: 0.2165 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.22354 to 0.21649, saving model to saved_models\\weights.best.basic_mlp.hdf5\n",
      "Epoch 87/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1940 - accuracy: 0.9246 - val_loss: 0.2420 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.21649\n",
      "Epoch 88/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1853 - accuracy: 0.9289 - val_loss: 0.2347 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.21649\n",
      "Epoch 89/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1705 - accuracy: 0.9361 - val_loss: 0.2402 - val_accuracy: 0.9096\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.21649\n",
      "Epoch 90/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1782 - accuracy: 0.9341 - val_loss: 0.2455 - val_accuracy: 0.9178\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.21649\n",
      "Epoch 91/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1803 - accuracy: 0.9330 - val_loss: 0.2425 - val_accuracy: 0.9130\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.21649\n",
      "Epoch 92/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1927 - accuracy: 0.9289 - val_loss: 0.2413 - val_accuracy: 0.9185\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.21649\n",
      "Epoch 93/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1845 - accuracy: 0.9343 - val_loss: 0.2381 - val_accuracy: 0.9198\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.21649\n",
      "Epoch 94/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1621 - accuracy: 0.9398 - val_loss: 0.2409 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.21649\n",
      "Epoch 95/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.1672 - accuracy: 0.9284 - val_loss: 0.2350 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.21649\n",
      "Epoch 96/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.1731 - accuracy: 0.9321 - val_loss: 0.2346 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.21649\n",
      "Epoch 97/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.1670 - accuracy: 0.9377 - val_loss: 0.2759 - val_accuracy: 0.9022\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.21649\n",
      "Epoch 98/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1842 - accuracy: 0.9257 - val_loss: 0.2393 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.21649\n",
      "Epoch 99/100\n",
      "138/138 [==============================] - 1s 6ms/step - loss: 0.1590 - accuracy: 0.9361 - val_loss: 0.2287 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.21649\n",
      "Epoch 100/100\n",
      "138/138 [==============================] - 1s 7ms/step - loss: 0.1636 - accuracy: 0.9350 - val_loss: 0.2240 - val_accuracy: 0.9327\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.21649\n",
      "Training completed in time:  0:01:41.823057\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_val, y_val), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0663648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9719203114509583\n",
      "Validation Accuracy:  0.932744562625885\n",
      "Testing Accuracy:  0.9219280481338501\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"Validation Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f800f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['General Sound' 'Illegal Voice' 'Legal Voice']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[476   2  74]\n",
      " [  5 318  10]\n",
      " [ 14  10 564]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "General Sound       0.96      0.86      0.91       552\n",
      "Illegal Voice       0.96      0.95      0.96       333\n",
      "  Legal Voice       0.87      0.96      0.91       588\n",
      "\n",
      "     accuracy                           0.92      1473\n",
      "    macro avg       0.93      0.93      0.93      1473\n",
      " weighted avg       0.93      0.92      0.92      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(le.classes_)\n",
    "\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = model.predict_classes(x_test)\n",
    "confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "print(confusion_mat)\n",
    "\n",
    "plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.cm.gray)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "ticks = np.arange(3)\n",
    "plt.xticks(ticks, ticks)\n",
    "plt.yticks(ticks, ticks)\n",
    "plt.ylabel('True labels')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644c0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(file_name):\n",
    "    prediction_feature = np.array([extract_features(file_name)])\n",
    "\n",
    "    predicted_vector = model.predict_classes(prediction_feature)\n",
    "    predicted_class = le.inverse_transform(predicted_vector) \n",
    "    print(\"The predicted class is:\", predicted_class[0], '\\n') \n",
    "\n",
    "    predicted_proba_vector = model.predict_proba(prediction_feature) \n",
    "    predicted_proba = predicted_proba_vector[0]\n",
    "    for i in range(len(predicted_proba)): \n",
    "        category = le.inverse_transform(np.array([i]))\n",
    "        print(category[0], \"\\t\\t : \", format(predicted_proba[i], '.32f') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9fa28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: Illegal Voice \n",
      "\n",
      "General Sound \t\t :  0.10170454531908035278320312500000\n",
      "Illegal Voice \t\t :  0.46201741695404052734375000000000\n",
      "Legal Voice \t\t :  0.43627810478210449218750000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "filename = 'V-YT-PSY-006051.wav'\n",
    "# Legal\n",
    "print_prediction(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da318c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
